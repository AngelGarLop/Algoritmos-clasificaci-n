{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T11:25:22.264983Z",
     "iopub.status.busy": "2025-03-04T11:25:22.264705Z",
     "iopub.status.idle": "2025-03-04T11:25:22.269657Z",
     "shell.execute_reply": "2025-03-04T11:25:22.268683Z",
     "shell.execute_reply.started": "2025-03-04T11:25:22.264963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, log_loss, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import kagglehub\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación de los algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo de aprendisaje supervisado que se usa para los modelos de clasificación y de regresión lineal. Crea un hiperplano(recta) que separe los dos conjuntos de datos con la mayor separción posible como se puede ver en la siguiente ![GitHub Logo](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/277px-Svm_separating_hyperplanes_%28SVG%29.svg.png)\n",
    "En la imagen anterior se cogería el h3 porque el h1 no los divide bien y el h2 tiene menor separación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logistica es un modelo que sirve para predecir si un dato pertenece a una ctegoría o a otra en unfucionede unas variables independientes, se diferencia de una regresion lineal en que la logistica te da un nos porcentajes mientras que la lineal te da números.\n",
    "\n",
    "$$\n",
    "P(Y=1) = \\frac{1}{1 + e^{-(b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n)}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* P(Y=1)P(Y=1) es la probabilidad de que algo ocurra (por ejemplo, que compre el producto).\n",
    "*    b0 es el término de sesgo (como un punto de inicio).\n",
    "*    b1​,b2​,...,bn​ son los pesos de cada variable (edad, salario, etc.).\n",
    "*    X1​,X2​,...,Xn​ son los valores de esas variables para cada persona.\n",
    "*    e es una constante matemática (~2.718).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la siguiente imagen un arbol de decisión es un modelo de aprendizaje en que se forman diagramas de construcciones lógicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GitHub Logo](https://upload.wikimedia.org/wikipedia/commons/e/e6/Arbol_de_decision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosques aleatorios "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo de bosque aleatorio son varios arbloes de decisón puestos juntos, cada uno es entrenado con un parte de los datos y  despues hace que voten para escoger la mejor decisón\n",
    "![GitHub Logo](https://miro.medium.com/v2/resize:fit:640/format:webp/0*Z52NbkU3Uddq3gX7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN, o el algoritmo de k vecino más cercano "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un modelo de clasificación que mira los k vecinos más cercanos donde K es el número de vecinos. Las ecuaciones más usadas para calcular la distacia del punto con los más cercanas son la euclidiana y la Manhattan, puedes usar la ecuación de Minkowski para poder usar las dos cambiando solo un parámetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Distancia Euclidiana**\n",
    "$$ d(A, B) = \\sqrt{\\sum_{i=1}^{n} (x_i^{(A)} - x_i^{(B)})^2} $$\n",
    "\n",
    "#### **Distancia de Manhattan**\n",
    "$$ d(A, B) = \\sum_{i=1}^{n} |x_i^{(A)} - x_i^{(B)}| $$\n",
    "\n",
    "#### **Distancia de Minkowski**\n",
    "$$ d(A, B) = \\left( \\sum_{i=1}^{n} |x_i^{(A)} - x_i^{(B)}|^p \\right)^{\\frac{1}{p}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicación de los algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos sin hyperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponemos un RANDOM_STATE para a la hora de comprar los modelos tengan todos la misma semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "breast_cancer_wisconsin_diagnostic_dataset_path = kagglehub.dataset_download('utkarshx27/breast-cancer-wisconsin-diagnostic-dataset')\n",
    "wine_quality_dataset_path = kagglehub.dataset_download('yasserh/wine-quality-dataset')\n",
    "accidentes_de_trfico_de_madrid_espaa_2019_a_2023_path = kagglehub.dataset_download('jairoordezpacheco/accidentes-de-trfico-de-madrid-espaa-2019-a-2023')\n",
    "phishing_website_detector_path = kagglehub.dataset_download('eswarchandt/phishing-website-detector')\n",
    "\n",
    "brca = pd.read_csv(breast_cancer_wisconsin_diagnostic_dataset_path+'/brca.csv')\n",
    "wine = pd.read_csv(wine_quality_dataset_path+'/WineQT.csv')\n",
    "phishing= pd.read_csv(phishing_website_detector_path+'/phishing.csv')\n",
    "accidents = pd.read_csv(accidentes_de_trfico_de_madrid_espaa_2019_a_2023_path+'/datos_madrid.csv',encoding='MacRoman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos para pasarselos a los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_brca(df):\n",
    "    X = df.drop(columns=['y'])\n",
    "    y = df['y'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_wine(df):\n",
    "    df['quality'] = df['quality'].apply(lambda x: 1 if x > 5 else 0)\n",
    "    X = df.drop(columns=['quality', 'Id'])\n",
    "    y = df['quality']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_phishing(df):\n",
    "    X = df.drop(columns=['class', 'Index'])\n",
    "    y = df['class'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_accidents(df):\n",
    "    df = df.drop(columns=['localizacion','numero','distrito','lesividad'])\n",
    "    df = df.dropna()\n",
    "\n",
    "# Mapeo de códigos a 0 (leve) o 1 (grave)\n",
    "    mapa = {\n",
    "        0: 0,  # LEVE\n",
    "        1: 0,  # LEVE\n",
    "        2: 0,  # LEVE\n",
    "        3: 1,  # GRAVE\n",
    "        4: 1,  # FALLECIDO (considerado grave)\n",
    "        5: 0,  # LEVE\n",
    "        6: 0,  # LEVE\n",
    "        7: 0,  # LEVE\n",
    "        14: 0, # Sin asistencia -> 0\n",
    "        77: 0  # Se desconoce -> 0\n",
    "    }\n",
    "\n",
    "\n",
    "    df['cod_lesividad'] = df['cod_lesividad'].map(mapa)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "    df.to_csv('accidents2.csv', index=False)        \n",
    "    X = df.drop(columns=['cod_lesividad'])\n",
    "    y = df['cod_lesividad']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_brca, y_brca = preprocess_brca(brca)\n",
    "X_wine, y_wine = preprocess_wine(wine)\n",
    "X_phishing, y_phishing = preprocess_phishing(phishing)\n",
    "X_accidents, y_accidents = preprocess_accidents(accidents.head(20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos entre datos de test y de entrnamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_brca, X_test_brca, y_train_brca, y_test_brca = train_test_split(X_brca, y_brca, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine, y_wine, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train_phishing, X_test_phishing, y_train_phishing, y_test_phishing = train_test_split(X_phishing, y_phishing, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train_accidents, X_test_accidents, y_train_accidents, y_test_accidents = train_test_split(X_accidents, y_accidents, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos los dato de entrada de todos los datasets menos del de phishing que viene ya normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_brca = scaler.fit_transform(X_train_brca)\n",
    "X_test_brca = scaler.transform(X_test_brca)\n",
    "X_train_wine = scaler.fit_transform(X_train_wine)\n",
    "X_test_wine = scaler.transform(X_test_wine)\n",
    "X_train_accidents = scaler.fit_transform(X_train_accidents)\n",
    "X_test_accidents = scaler.transform(X_test_accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el metodo para evaluar los modelos con todas las metricas más dos nuevas que a continuación explicaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC :La métrica ROC AUC mide la capacidad de un modelo para diferenciar entre clases. Específicamente, es el área bajo la curva ROC, que es un gráfico que muestra la relación entre la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR) a diferentes umbrales de clasificación.\n",
    "\n",
    "Matriz de Confusión La matriz de confusión es una tabla que se utiliza para describir el rendimiento de un modelo de clasificación. Muestra el número de predicciones correctas e incorrectas desglosadas por cada clase.\n",
    "\n",
    "Componentes de la Matriz de Confusión:\n",
    "True Positives (TP): Casos positivos correctamente clasificados.\n",
    "True Negatives (TN): Casos negativos correctamente clasificados.\n",
    "False Positives (FP): Casos negativos incorrectamente clasificados como positivos.\n",
    "False Negatives (FN): Casos positivos incorrectamente clasificados como negativos.\n",
    "\n",
    "[[TN, FP],\n",
    "\n",
    " [FN, TP]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos={}\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    modelos[model_name] = deepcopy(model)\n",
    "    return accuracy, precision, recall, f1, roc_auc, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(random_state=RANDOM_STATE)\n",
    "log_reg = LogisticRegression(random_state=RANDOM_STATE)\n",
    "decision_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "random_forest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los modelos y los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'BRCA': (X_train_brca, X_test_brca, y_train_brca, y_test_brca),\n",
    "    'Wine': (X_train_wine, X_test_wine, y_train_wine, y_test_wine),\n",
    "    'Phishing': (X_train_phishing, X_test_phishing, y_train_phishing, y_test_phishing),\n",
    "    'Accidents': (X_train_accidents, X_test_accidents, y_train_accidents, y_test_accidents)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'SVM': svm,\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Decision Tree': decision_tree,\n",
    "    'Random Forest': random_forest,\n",
    "    'kNN': knn\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos los modelos con los datos de los datasets y los guardamos en un diccionario para poder mostralos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for dataset_name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    results[dataset_name] = {}\n",
    "    for model_name, model in models.items():\n",
    "        accuracy, precision, recall, f1, roc_auc, cm = evaluate_model(model, X_train, X_test, y_train, y_test, dataset_name+\"_\"+model_name)\n",
    "        results[dataset_name][model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'Confusion Matrix': cm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BRCA dataset:\n",
      "  SVM:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Decision Tree:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  kNN:\n",
      "    Accuracy: 0.9736842105263158\n",
      "    Precision: 0.9787234042553191\n",
      "    Recall: 0.9583333333333334\n",
      "    F1 Score: 0.968421052631579\n",
      "    ROC AUC: 0.9715909090909092\n",
      "    Confusion Matrix: [[65  1]\n",
      " [ 2 46]]\n",
      "\n",
      "Results for Wine dataset:\n",
      "  SVM:\n",
      "    Accuracy: 0.7860262008733624\n",
      "    Precision: 0.782608695652174\n",
      "    Recall: 0.7894736842105263\n",
      "    F1 Score: 0.7860262008733624\n",
      "    ROC AUC: 0.7860411899313502\n",
      "    Confusion Matrix: [[90 25]\n",
      " [24 90]]\n",
      "\n",
      "  Logistic Regression:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7614678899082569\n",
      "    Recall: 0.7280701754385965\n",
      "    F1 Score: 0.7443946188340808\n",
      "    ROC AUC: 0.7509916094584287\n",
      "    Confusion Matrix: [[89 26]\n",
      " [31 83]]\n",
      "\n",
      "  Decision Tree:\n",
      "    Accuracy: 0.7467248908296943\n",
      "    Precision: 0.7857142857142857\n",
      "    Recall: 0.6754385964912281\n",
      "    F1 Score: 0.7264150943396226\n",
      "    ROC AUC: 0.7464149504195271\n",
      "    Confusion Matrix: [[94 21]\n",
      " [37 77]]\n",
      "\n",
      "  Random Forest:\n",
      "    Accuracy: 0.7947598253275109\n",
      "    Precision: 0.8018018018018018\n",
      "    Recall: 0.7807017543859649\n",
      "    F1 Score: 0.7911111111111111\n",
      "    ROC AUC: 0.794698703279939\n",
      "    Confusion Matrix: [[93 22]\n",
      " [25 89]]\n",
      "\n",
      "  kNN:\n",
      "    Accuracy: 0.7205240174672489\n",
      "    Precision: 0.7016129032258065\n",
      "    Recall: 0.7631578947368421\n",
      "    F1 Score: 0.7310924369747899\n",
      "    ROC AUC: 0.7207093821510298\n",
      "    Confusion Matrix: [[78 37]\n",
      " [27 87]]\n",
      "\n",
      "Results for Phishing dataset:\n",
      "  SVM:\n",
      "    Accuracy: 0.9479873360470376\n",
      "    Precision: 0.9408517350157729\n",
      "    Recall: 0.967558799675588\n",
      "    F1 Score: 0.9540183926429429\n",
      "    ROC AUC: 0.9454358415555854\n",
      "    Confusion Matrix: [[ 903   75]\n",
      " [  40 1193]]\n",
      "\n",
      "  Logistic Regression:\n",
      "    Accuracy: 0.9262777023971054\n",
      "    Precision: 0.9246031746031746\n",
      "    Recall: 0.9448499594484996\n",
      "    F1 Score: 0.9346169273967108\n",
      "    ROC AUC: 0.9238564725667856\n",
      "    Confusion Matrix: [[ 883   95]\n",
      " [  68 1165]]\n",
      "\n",
      "  Decision Tree:\n",
      "    Accuracy: 0.9624604251469923\n",
      "    Precision: 0.9637096774193549\n",
      "    Recall: 0.9691808596918086\n",
      "    F1 Score: 0.9664375252729478\n",
      "    ROC AUC: 0.9615842948765791\n",
      "    Confusion Matrix: [[ 933   45]\n",
      " [  38 1195]]\n",
      "\n",
      "  Random Forest:\n",
      "    Accuracy: 0.9751243781094527\n",
      "    Precision: 0.9765372168284789\n",
      "    Recall: 0.9789132197891321\n",
      "    F1 Score: 0.9777237748076144\n",
      "    ROC AUC: 0.9746304340254454\n",
      "    Confusion Matrix: [[ 949   29]\n",
      " [  26 1207]]\n",
      "\n",
      "  kNN:\n",
      "    Accuracy: 0.9466304839439168\n",
      "    Precision: 0.9499596448748991\n",
      "    Recall: 0.9545823195458232\n",
      "    F1 Score: 0.9522653721682848\n",
      "    ROC AUC: 0.9455938182596191\n",
      "    Confusion Matrix: [[ 916   62]\n",
      " [  56 1177]]\n",
      "\n",
      "Results for Accidents dataset:\n",
      "  SVM:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Decision Tree:\n",
      "    Accuracy: 0.9773982923154194\n",
      "    Precision: 0.07936507936507936\n",
      "    Recall: 0.13513513513513514\n",
      "    F1 Score: 0.1\n",
      "    ROC AUC: 0.560216490254513\n",
      "    Confusion Matrix: [[3887   58]\n",
      " [  32    5]]\n",
      "\n",
      "  Random Forest:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  kNN:\n",
      "    Accuracy: 0.9902059266700151\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.4997465145754119\n",
      "    Confusion Matrix: [[3943    2]\n",
      " [  37    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_results in results.items():\n",
    "    print(f\"Results for {dataset_name} dataset:\")\n",
    "    for model_name, metrics in dataset_results.items():\n",
    "        print(f\"  {model_name}:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"    {metric_name}: {value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de BRCA dataset:\n",
    "\n",
    "* SVM y Logistic Regression: Ambos modelos tienen un rendimiento muy alto, con precisión perfecta  (De todos los casos que los modelos predijeron como positivos, el 100% eran realmente positivos) y un recall ligeramente menor(Los dos modelos fallaron y tu vieron 1 falso negativo), lo que indica que clasifican correctamente casi todos los casos positivos y negativos.\n",
    "* Decision Tree y Random Forest: Ambos modelos tienen un rendimiento perfecto en todas las métricas, por lo que seguramente esten sobreajustados.\n",
    "* kNN: Tiene un rendimiento ligeramente inferior en comparación con los otros modelos, pero aún así es bastante alto con una precisión y recall muy buenos.\n",
    "\n",
    "* Viendo los resultado anteriormente descritos yo me quedaría con el SVM o la regresión logistica porque no están sobreajustados, para escoger alguno habría que ver el rendimiento de cada uno de los dos modelos y cual gasta más"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de Wine dataset:\n",
    "* SVM y Random Forest: Ambos modelos tienen el mejor rendimiento en este dataset, con SVM ligeramente inferior a Random Forest en precisión y recall.\n",
    "* Logistic Regression y Decision Tree: Tienen un rendimiento aceptable, pero inferior a SVM y Random Forest. Decision Tree tiene un recall más bajo, lo que indica que no clasifica tan bien los casos positivos.\n",
    "* kNN: Tiene el rendimiento más bajo en comparación con los otros modelos, con una precisión y recall más bajos.\n",
    "* Viendo los resultados anteriormente descritos yo me quedaría con random forest porque es ligeramente superior al SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de Phishing Dataset\n",
    "* Random Forest: Tiene el mejor rendimiento en este dataset, con la mayor precisión y recall, lo que indica que clasifica correctamente la mayoría de los casos positivos y negativos.\n",
    "* Decision Tree y SVM: Tienen un rendimiento muy alto, con precisión y recall ligeramente inferiores a Random Forest.\n",
    "* Logistic Regression: Tiene un rendimiento aceptable, pero inferior a Random Forest, Decision Tree y SVM.\n",
    "kNN: Tiene un rendimiento similar a SVM, con una precisión y recall muy buenos.\n",
    "* Viendo los resultados anteriormente descritos yo me quedaría con random forest porque es claramente superior a los demás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión Accidents dataset\n",
    "\n",
    "* SVM, Logistic Regression y Random Forest: Todos estos modelos tienen una alta precisión en términos de clasificar los negativos, pero no identifican correctamente ningún caso positivo, lo que se refleja en las métricas de precisión, recall y F1 score de 0.\n",
    "* Decision Tree: Tiene un rendimiento ligeramente mejor en términos de identificar casos positivos, pero aún así es bastante bajo.\n",
    "* kNN: Similar a SVM, Logistic Regression y Random Forest, no identifica correctamente ningún caso positivo.\n",
    "* Viendo los resultado anteriormente descritos, aunque son datos pobres el mejor modelo es el arbo,l de decisió que detecta algun positivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos con hyperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los modelos con los hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero empezamos por el SVM y he usado los siguientes hiperparámtros:\n",
    "\n",
    "* C: Controla cuánto permitimos que los puntos estén en el lado incorrecto de la línea. Un valor alto de C intenta clasificar todos los puntos correctamente, mientras que un valor bajo permite más errores pero puede generalizar mejor. El valor por defecto es 1\n",
    "* kernel: Define cómo se transforman los datos para encontrar la mejor línea de separación. Puede ser lineal o no lineal, en nuestro caso hemos usado el kernel linal que se usa cuando los datos e pueden dividir facilmente por una linea y el rbf que se usa cuando hay datos que no se pueden separar fácilmente con una recta y lo que hace es crear un espacio de una dimensión mayor para poder dividirlo por una linea.\n",
    "* tol: Es la tolerancia para el criterio de parada. Controla cuándo el algoritmo debe detenerse. Un valor más pequeño significa que el algoritmo se detendrá solo cuando los cambios sean muy pequeños, lo que puede llevar a un ajuste más preciso pero también a un tiempo de entrenamiento más largo. El valor por defecto es 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar los modelos con un hiperparámetro específico por ejecución\n",
    "svm_C_10 = SVC(C=10.0, random_state=RANDOM_STATE)\n",
    "svm_C_0_1 = SVC(C=0.1, random_state=RANDOM_STATE)\n",
    "svm_kernel_linear = SVC(kernel='linear', random_state=RANDOM_STATE)\n",
    "svm_kernel_rbf = SVC(kernel='rbf', random_state=RANDOM_STATE)\n",
    "svm_tol_1e_0_1 = SVC(tol=0.1, random_state=RANDOM_STATE)\n",
    "svm_tol_1e_6 = SVC(tol=1e-6, random_state=RANDOM_STATE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la regresioón logistica he usado los siguientes hiperparámetros:\n",
    "\n",
    "* C: Controla cuánto penalizamos la complejidad del modelo. Un valor alto de C intenta ajustar el modelo muy bien a los datos, mientras que un valor bajo lo hace más simple y puede generalizar mejor a nuevos datos. El valor por defecto es 1\n",
    "\n",
    "* solver: Es el método que se usa para encontrar los mejores valores para el modelo. Por ejemplo, 'liblinear' es bueno para conjuntos de datos pequeños, mientras que 'lbfgs' es más adecuado para conjuntos de datos más grandes.\n",
    "\n",
    "* max_iter: Es el número máximo de veces que el método intentará ajustar el modelo. Si el modelo no converge antes de alcanzar este número, se detendrá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_C_1_0 = LogisticRegression(C=10.0, random_state=RANDOM_STATE)\n",
    "log_reg_C_0_1 = LogisticRegression(C=0.1, random_state=RANDOM_STATE)\n",
    "log_reg_solver_liblinear = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "log_reg_solver_lbfgs = LogisticRegression(solver='lbfgs', random_state=RANDOM_STATE)\n",
    "log_reg_max_iter_200 = LogisticRegression(max_iter=200, random_state=RANDOM_STATE)\n",
    "log_reg_max_iter_100 = LogisticRegression(max_iter=100, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los arboles de decisión he usado los siguiente hiperparámetros:\n",
    "\n",
    "* max_depth: La profundidad máxima del árbol, es decir, cuántas preguntas puede hacer antes de llegar a una decisión. Un valor más alto puede llevar a un modelo más complejo y específico, mientras que un valor más bajo puede hacer que el modelo sea más simple y general. \n",
    "\n",
    "* min_samples_split: El número mínimo de datos necesarios para hacer una nueva pregunta. Si un nodo tiene menos datos que este número, no se dividirá. Por defecto está puesto en 2\n",
    "\n",
    "* min_samples_leaf: El número mínimo de datos necesarios para que una hoja sea válida. Esto ayuda a evitar que el modelo se ajuste demasiado a los datos de entrenamiento. Por defecto está puesto en 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_max_depth_10 = DecisionTreeClassifier(max_depth=10, random_state=RANDOM_STATE)\n",
    "decision_tree_max_depth_5 = DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)\n",
    "decision_tree_min_samples_split_8 = DecisionTreeClassifier(min_samples_split=8, random_state=RANDOM_STATE)\n",
    "decision_tree_min_samples_split_4 = DecisionTreeClassifier(min_samples_split=4, random_state=RANDOM_STATE)\n",
    "decision_tree_min_samples_leaf_0_5 = DecisionTreeClassifier(min_samples_leaf=0.5, random_state=RANDOM_STATE)\n",
    "decision_tree_min_samples_leaf_5 = DecisionTreeClassifier(min_samples_leaf=5, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los bosques aleatorios he usado los siguiente hiperparámetros:\n",
    "\n",
    "* n_estimators: El número de árboles en el bosque. Más árboles pueden llevar a un modelo más preciso, pero también aumentan el tiempo de entrenamiento. Por defecto está puesto en 1\n",
    "\n",
    "* max_depth: La profundidad máxima de cada árbol. Controla cuántas preguntas puede hacer cada árbol antes de llegar a una decisión.\n",
    "\n",
    "* min_samples_split: El número mínimo de datos necesarios para hacer una nueva pregunta en cada árbol. Ayuda a controlar la complejidad de los árboles individuales. Por defecto está puesto en 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_n_estimators_200 = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "random_forest_n_estimators_100 = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "random_forest_max_depth_10 = RandomForestClassifier(max_depth=10, random_state=RANDOM_STATE)\n",
    "random_forest_max_depth_5 = RandomForestClassifier(max_depth=5, random_state=RANDOM_STATE)\n",
    "random_forest_min_samples_split_8 = RandomForestClassifier(min_samples_split=8, random_state=RANDOM_STATE)\n",
    "random_forest_min_samples_split_4 = RandomForestClassifier(min_samples_split=4, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* n_neighbors: El número de puntos cercanos a considerar para tomar la decisión. Un valor más alto puede hacer que el modelo sea más general, mientras que un valor más bajo puede hacer que el modelo sea más específico. Por defecto está puesto en 5\n",
    "\n",
    "* weights: Cómo se ponderan los puntos cercanos. 'uniform' significa que todos los puntos tienen el mismo peso, mientras que 'distance' significa que los puntos más cercanos tienen más peso. por defecto está puesto en uniform\n",
    "\n",
    "* metric: La forma en que se mide la distancia entre los puntos. Por ejemplo, 'euclidean' para la distancia euclidiana (línea recta) y 'manhattan' para la distancia de manhattan (suma de las distancias horizontales y verticales). Por defecto está puesto en minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_n_neighbors_2 = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_n_neighbors_10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_weights_distance = KNeighborsClassifier(weights='distance')\n",
    "knn_weights_uniform = KNeighborsClassifier(weights='uniform')\n",
    "knn_metric_euclidean = KNeighborsClassifier(metric='euclidean')\n",
    "knn_metric_manhattan = KNeighborsClassifier(metric='manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamops los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_params = {\n",
    "    'SVM_C_10': svm_C_10,\n",
    "    'SVM_C_0_1': svm_C_0_1,\n",
    "    'SVM_kernel_linear': svm_kernel_linear,\n",
    "    'SVM_kernel_rbf': svm_kernel_rbf,\n",
    "    'SVM_tol_1e_3': svm_tol_1e_0_1,\n",
    "    'SVM_tol_1e_4': svm_tol_1e_6,\n",
    "    'Logistic Regression_C_1': log_reg_C_1_0,\n",
    "    'Logistic Regression_C_0_1': log_reg_C_0_1,\n",
    "    'Logistic Regression_solver_liblinear': log_reg_solver_liblinear,\n",
    "    'Logistic Regression_solver_lbfgs': log_reg_solver_lbfgs,\n",
    "    'Logistic Regression_max_iter_200': log_reg_max_iter_200,\n",
    "    'Logistic Regression_max_iter_100': log_reg_max_iter_100,\n",
    "    'Decision Tree_max_depth_10': decision_tree_max_depth_10,\n",
    "    'Decision Tree_max_depth_5': decision_tree_max_depth_5,\n",
    "    'Decision Tree_min_samples_split_4': decision_tree_min_samples_split_8,\n",
    "    'Decision Tree_min_samples_split_2': decision_tree_min_samples_split_4,\n",
    "    'Decision Tree_min_samples_leaf_2': decision_tree_min_samples_leaf_0_5,\n",
    "    'Decision Tree_min_samples_leaf_1': decision_tree_min_samples_leaf_5,\n",
    "    'Random Forest_n_estimators_200': random_forest_n_estimators_200,\n",
    "    'Random Forest_n_estimators_100': random_forest_n_estimators_100,\n",
    "    'Random Forest_max_depth_10': random_forest_max_depth_10,\n",
    "    'Random Forest_max_depth_5': random_forest_max_depth_5,\n",
    "    'Random Forest_min_samples_split_4': random_forest_min_samples_split_8,\n",
    "    'Random Forest_min_samples_split_2': random_forest_min_samples_split_4,\n",
    "    'kNN_n_neighbors_3': knn_n_neighbors_2,\n",
    "    'kNN_n_neighbors_5': knn_n_neighbors_10,\n",
    "    'kNN_weights_distance': knn_weights_distance,\n",
    "    'kNN_weights_uniform': knn_weights_uniform,\n",
    "    'kNN_metric_euclidean': knn_metric_euclidean,\n",
    "    'kNN_metric_manhattan': knn_metric_manhattan\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos los modelos con los datos de los hiperparametros y los guardamos en un diccionario para poder mostralos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results_with_params = {}\n",
    "\n",
    "for dataset_name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    results_with_params[dataset_name] = {}\n",
    "    for model_name, model in models_with_params.items():\n",
    "        accuracy, precision, recall, f1, roc_auc, cm = evaluate_model(model, X_train, X_test, y_train, y_test, dataset_name+\"_\"+model_name)\n",
    "        results_with_params[dataset_name][model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'Confusion Matrix': cm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BRCA dataset with hyperparameters:\n",
      "  SVM_C_10:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  SVM_C_0_1:\n",
      "    Accuracy: 0.956140350877193\n",
      "    Precision: 1.0\n",
      "    Recall: 0.8958333333333334\n",
      "    F1 Score: 0.945054945054945\n",
      "    ROC AUC: 0.9479166666666667\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 5 43]]\n",
      "\n",
      "  SVM_kernel_linear:\n",
      "    Accuracy: 0.9824561403508771\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9583333333333334\n",
      "    F1 Score: 0.9787234042553191\n",
      "    ROC AUC: 0.9791666666666667\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 2 46]]\n",
      "\n",
      "  SVM_kernel_rbf:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  SVM_tol_1e_3:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  SVM_tol_1e_4:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression_C_1:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression_C_0_1:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression_solver_liblinear:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression_solver_lbfgs:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression_max_iter_200:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Logistic Regression_max_iter_100:\n",
      "    Accuracy: 0.9912280701754386\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9791666666666666\n",
      "    F1 Score: 0.9894736842105263\n",
      "    ROC AUC: 0.9895833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 1 47]]\n",
      "\n",
      "  Decision Tree_max_depth_10:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Decision Tree_max_depth_5:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Decision Tree_min_samples_split_4:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Decision Tree_min_samples_split_2:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_2:\n",
      "    Accuracy: 0.5789473684210527\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[66  0]\n",
      " [48  0]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_1:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest_n_estimators_200:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest_n_estimators_100:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest_max_depth_10:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest_max_depth_5:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest_min_samples_split_4:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  Random Forest_min_samples_split_2:\n",
      "    Accuracy: 1.0\n",
      "    Precision: 1.0\n",
      "    Recall: 1.0\n",
      "    F1 Score: 1.0\n",
      "    ROC AUC: 1.0\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 0 48]]\n",
      "\n",
      "  kNN_n_neighbors_3:\n",
      "    Accuracy: 0.9385964912280702\n",
      "    Precision: 1.0\n",
      "    Recall: 0.8541666666666666\n",
      "    F1 Score: 0.9213483146067416\n",
      "    ROC AUC: 0.9270833333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 7 41]]\n",
      "\n",
      "  kNN_n_neighbors_5:\n",
      "    Accuracy: 0.9649122807017544\n",
      "    Precision: 0.9782608695652174\n",
      "    Recall: 0.9375\n",
      "    F1 Score: 0.9574468085106383\n",
      "    ROC AUC: 0.9611742424242424\n",
      "    Confusion Matrix: [[65  1]\n",
      " [ 3 45]]\n",
      "\n",
      "  kNN_weights_distance:\n",
      "    Accuracy: 0.9736842105263158\n",
      "    Precision: 0.9787234042553191\n",
      "    Recall: 0.9583333333333334\n",
      "    F1 Score: 0.968421052631579\n",
      "    ROC AUC: 0.9715909090909092\n",
      "    Confusion Matrix: [[65  1]\n",
      " [ 2 46]]\n",
      "\n",
      "  kNN_weights_uniform:\n",
      "    Accuracy: 0.9736842105263158\n",
      "    Precision: 0.9787234042553191\n",
      "    Recall: 0.9583333333333334\n",
      "    F1 Score: 0.968421052631579\n",
      "    ROC AUC: 0.9715909090909092\n",
      "    Confusion Matrix: [[65  1]\n",
      " [ 2 46]]\n",
      "\n",
      "  kNN_metric_euclidean:\n",
      "    Accuracy: 0.9736842105263158\n",
      "    Precision: 0.9787234042553191\n",
      "    Recall: 0.9583333333333334\n",
      "    F1 Score: 0.968421052631579\n",
      "    ROC AUC: 0.9715909090909092\n",
      "    Confusion Matrix: [[65  1]\n",
      " [ 2 46]]\n",
      "\n",
      "  kNN_metric_manhattan:\n",
      "    Accuracy: 0.9649122807017544\n",
      "    Precision: 1.0\n",
      "    Recall: 0.9166666666666666\n",
      "    F1 Score: 0.9565217391304348\n",
      "    ROC AUC: 0.9583333333333333\n",
      "    Confusion Matrix: [[66  0]\n",
      " [ 4 44]]\n",
      "\n",
      "Results for Wine dataset with hyperparameters:\n",
      "  SVM_C_10:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7522123893805309\n",
      "    Recall: 0.7456140350877193\n",
      "    F1 Score: 0.748898678414097\n",
      "    ROC AUC: 0.751067887109077\n",
      "    Confusion Matrix: [[87 28]\n",
      " [29 85]]\n",
      "\n",
      "  SVM_C_0_1:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.728\n",
      "    Recall: 0.7982456140350878\n",
      "    F1 Score: 0.7615062761506276\n",
      "    ROC AUC: 0.7512967200610221\n",
      "    Confusion Matrix: [[81 34]\n",
      " [23 91]]\n",
      "\n",
      "  SVM_kernel_linear:\n",
      "    Accuracy: 0.74235807860262\n",
      "    Precision: 0.7570093457943925\n",
      "    Recall: 0.7105263157894737\n",
      "    F1 Score: 0.7330316742081447\n",
      "    ROC AUC: 0.7422196796338673\n",
      "    Confusion Matrix: [[89 26]\n",
      " [33 81]]\n",
      "\n",
      "  SVM_kernel_rbf:\n",
      "    Accuracy: 0.7860262008733624\n",
      "    Precision: 0.782608695652174\n",
      "    Recall: 0.7894736842105263\n",
      "    F1 Score: 0.7860262008733624\n",
      "    ROC AUC: 0.7860411899313502\n",
      "    Confusion Matrix: [[90 25]\n",
      " [24 90]]\n",
      "\n",
      "  SVM_tol_1e_3:\n",
      "    Accuracy: 0.7860262008733624\n",
      "    Precision: 0.782608695652174\n",
      "    Recall: 0.7894736842105263\n",
      "    F1 Score: 0.7860262008733624\n",
      "    ROC AUC: 0.7860411899313502\n",
      "    Confusion Matrix: [[90 25]\n",
      " [24 90]]\n",
      "\n",
      "  SVM_tol_1e_4:\n",
      "    Accuracy: 0.7860262008733624\n",
      "    Precision: 0.782608695652174\n",
      "    Recall: 0.7894736842105263\n",
      "    F1 Score: 0.7860262008733624\n",
      "    ROC AUC: 0.7860411899313502\n",
      "    Confusion Matrix: [[90 25]\n",
      " [24 90]]\n",
      "\n",
      "  Logistic Regression_C_1:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7614678899082569\n",
      "    Recall: 0.7280701754385965\n",
      "    F1 Score: 0.7443946188340808\n",
      "    ROC AUC: 0.7509916094584287\n",
      "    Confusion Matrix: [[89 26]\n",
      " [31 83]]\n",
      "\n",
      "  Logistic Regression_C_0_1:\n",
      "    Accuracy: 0.7554585152838428\n",
      "    Precision: 0.7636363636363637\n",
      "    Recall: 0.7368421052631579\n",
      "    F1 Score: 0.75\n",
      "    ROC AUC: 0.7553775743707094\n",
      "    Confusion Matrix: [[89 26]\n",
      " [30 84]]\n",
      "\n",
      "  Logistic Regression_solver_liblinear:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7614678899082569\n",
      "    Recall: 0.7280701754385965\n",
      "    F1 Score: 0.7443946188340808\n",
      "    ROC AUC: 0.7509916094584287\n",
      "    Confusion Matrix: [[89 26]\n",
      " [31 83]]\n",
      "\n",
      "  Logistic Regression_solver_lbfgs:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7614678899082569\n",
      "    Recall: 0.7280701754385965\n",
      "    F1 Score: 0.7443946188340808\n",
      "    ROC AUC: 0.7509916094584287\n",
      "    Confusion Matrix: [[89 26]\n",
      " [31 83]]\n",
      "\n",
      "  Logistic Regression_max_iter_200:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7614678899082569\n",
      "    Recall: 0.7280701754385965\n",
      "    F1 Score: 0.7443946188340808\n",
      "    ROC AUC: 0.7509916094584287\n",
      "    Confusion Matrix: [[89 26]\n",
      " [31 83]]\n",
      "\n",
      "  Logistic Regression_max_iter_100:\n",
      "    Accuracy: 0.7510917030567685\n",
      "    Precision: 0.7614678899082569\n",
      "    Recall: 0.7280701754385965\n",
      "    F1 Score: 0.7443946188340808\n",
      "    ROC AUC: 0.7509916094584287\n",
      "    Confusion Matrix: [[89 26]\n",
      " [31 83]]\n",
      "\n",
      "  Decision Tree_max_depth_10:\n",
      "    Accuracy: 0.7161572052401747\n",
      "    Precision: 0.7333333333333333\n",
      "    Recall: 0.6754385964912281\n",
      "    F1 Score: 0.7031963470319634\n",
      "    ROC AUC: 0.7159801678108314\n",
      "    Confusion Matrix: [[87 28]\n",
      " [37 77]]\n",
      "\n",
      "  Decision Tree_max_depth_5:\n",
      "    Accuracy: 0.7074235807860262\n",
      "    Precision: 0.719626168224299\n",
      "    Recall: 0.6754385964912281\n",
      "    F1 Score: 0.6968325791855203\n",
      "    ROC AUC: 0.7072845156369184\n",
      "    Confusion Matrix: [[85 30]\n",
      " [37 77]]\n",
      "\n",
      "  Decision Tree_min_samples_split_4:\n",
      "    Accuracy: 0.7379912663755459\n",
      "    Precision: 0.7596153846153846\n",
      "    Recall: 0.6929824561403509\n",
      "    F1 Score: 0.7247706422018348\n",
      "    ROC AUC: 0.7377955758962625\n",
      "    Confusion Matrix: [[90 25]\n",
      " [35 79]]\n",
      "\n",
      "  Decision Tree_min_samples_split_2:\n",
      "    Accuracy: 0.7205240174672489\n",
      "    Precision: 0.7604166666666666\n",
      "    Recall: 0.6403508771929824\n",
      "    F1 Score: 0.6952380952380952\n",
      "    ROC AUC: 0.7201754385964912\n",
      "    Confusion Matrix: [[92 23]\n",
      " [41 73]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_2:\n",
      "    Accuracy: 0.5982532751091703\n",
      "    Precision: 0.6057692307692307\n",
      "    Recall: 0.5526315789473685\n",
      "    F1 Score: 0.5779816513761468\n",
      "    ROC AUC: 0.5980549199084669\n",
      "    Confusion Matrix: [[74 41]\n",
      " [51 63]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_1:\n",
      "    Accuracy: 0.759825327510917\n",
      "    Precision: 0.7657657657657657\n",
      "    Recall: 0.7456140350877193\n",
      "    F1 Score: 0.7555555555555555\n",
      "    ROC AUC: 0.75976353928299\n",
      "    Confusion Matrix: [[89 26]\n",
      " [29 85]]\n",
      "\n",
      "  Random Forest_n_estimators_200:\n",
      "    Accuracy: 0.7903930131004366\n",
      "    Precision: 0.8\n",
      "    Recall: 0.7719298245614035\n",
      "    F1 Score: 0.7857142857142857\n",
      "    ROC AUC: 0.7903127383676583\n",
      "    Confusion Matrix: [[93 22]\n",
      " [26 88]]\n",
      "\n",
      "  Random Forest_n_estimators_100:\n",
      "    Accuracy: 0.7947598253275109\n",
      "    Precision: 0.8018018018018018\n",
      "    Recall: 0.7807017543859649\n",
      "    F1 Score: 0.7911111111111111\n",
      "    ROC AUC: 0.794698703279939\n",
      "    Confusion Matrix: [[93 22]\n",
      " [25 89]]\n",
      "\n",
      "  Random Forest_max_depth_10:\n",
      "    Accuracy: 0.8034934497816594\n",
      "    Precision: 0.8053097345132744\n",
      "    Recall: 0.7982456140350878\n",
      "    F1 Score: 0.801762114537445\n",
      "    ROC AUC: 0.8034706331045004\n",
      "    Confusion Matrix: [[93 22]\n",
      " [23 91]]\n",
      "\n",
      "  Random Forest_max_depth_5:\n",
      "    Accuracy: 0.7860262008733624\n",
      "    Precision: 0.7876106194690266\n",
      "    Recall: 0.7807017543859649\n",
      "    F1 Score: 0.7841409691629956\n",
      "    ROC AUC: 0.786003051106026\n",
      "    Confusion Matrix: [[91 24]\n",
      " [25 89]]\n",
      "\n",
      "  Random Forest_min_samples_split_4:\n",
      "    Accuracy: 0.8122270742358079\n",
      "    Precision: 0.8141592920353983\n",
      "    Recall: 0.8070175438596491\n",
      "    F1 Score: 0.8105726872246696\n",
      "    ROC AUC: 0.8122044241037375\n",
      "    Confusion Matrix: [[94 21]\n",
      " [22 92]]\n",
      "\n",
      "  Random Forest_min_samples_split_2:\n",
      "    Accuracy: 0.7903930131004366\n",
      "    Precision: 0.8\n",
      "    Recall: 0.7719298245614035\n",
      "    F1 Score: 0.7857142857142857\n",
      "    ROC AUC: 0.7903127383676583\n",
      "    Confusion Matrix: [[93 22]\n",
      " [26 88]]\n",
      "\n",
      "  kNN_n_neighbors_3:\n",
      "    Accuracy: 0.74235807860262\n",
      "    Precision: 0.8160919540229885\n",
      "    Recall: 0.6228070175438597\n",
      "    F1 Score: 0.7064676616915423\n",
      "    ROC AUC: 0.7418382913806255\n",
      "    Confusion Matrix: [[99 16]\n",
      " [43 71]]\n",
      "\n",
      "  kNN_n_neighbors_5:\n",
      "    Accuracy: 0.7336244541484717\n",
      "    Precision: 0.7431192660550459\n",
      "    Recall: 0.7105263157894737\n",
      "    F1 Score: 0.726457399103139\n",
      "    ROC AUC: 0.7335240274599543\n",
      "    Confusion Matrix: [[87 28]\n",
      " [33 81]]\n",
      "\n",
      "  kNN_weights_distance:\n",
      "    Accuracy: 0.7554585152838428\n",
      "    Precision: 0.7338709677419355\n",
      "    Recall: 0.7982456140350878\n",
      "    F1 Score: 0.7647058823529411\n",
      "    ROC AUC: 0.7556445461479786\n",
      "    Confusion Matrix: [[82 33]\n",
      " [23 91]]\n",
      "\n",
      "  kNN_weights_uniform:\n",
      "    Accuracy: 0.7205240174672489\n",
      "    Precision: 0.7016129032258065\n",
      "    Recall: 0.7631578947368421\n",
      "    F1 Score: 0.7310924369747899\n",
      "    ROC AUC: 0.7207093821510298\n",
      "    Confusion Matrix: [[78 37]\n",
      " [27 87]]\n",
      "\n",
      "  kNN_metric_euclidean:\n",
      "    Accuracy: 0.7205240174672489\n",
      "    Precision: 0.7016129032258065\n",
      "    Recall: 0.7631578947368421\n",
      "    F1 Score: 0.7310924369747899\n",
      "    ROC AUC: 0.7207093821510298\n",
      "    Confusion Matrix: [[78 37]\n",
      " [27 87]]\n",
      "\n",
      "  kNN_metric_manhattan:\n",
      "    Accuracy: 0.7161572052401747\n",
      "    Precision: 0.6842105263157895\n",
      "    Recall: 0.7982456140350878\n",
      "    F1 Score: 0.7368421052631579\n",
      "    ROC AUC: 0.7165141113653699\n",
      "    Confusion Matrix: [[73 42]\n",
      " [23 91]]\n",
      "\n",
      "Results for Phishing dataset with hyperparameters:\n",
      "  SVM_C_10:\n",
      "    Accuracy: 0.9706015377657169\n",
      "    Precision: 0.9664536741214057\n",
      "    Recall: 0.981346309813463\n",
      "    F1 Score: 0.9738430583501007\n",
      "    ROC AUC: 0.9692007622686948\n",
      "    Confusion Matrix: [[ 936   42]\n",
      " [  23 1210]]\n",
      "\n",
      "  SVM_C_0_1:\n",
      "    Accuracy: 0.926729986431479\n",
      "    Precision: 0.9206598586017282\n",
      "    Recall: 0.9505271695052717\n",
      "    F1 Score: 0.9353551476456504\n",
      "    ROC AUC: 0.9236275929325949\n",
      "    Confusion Matrix: [[ 877  101]\n",
      " [  61 1172]]\n",
      "\n",
      "  SVM_kernel_linear:\n",
      "    Accuracy: 0.9253731343283582\n",
      "    Precision: 0.9224683544303798\n",
      "    Recall: 0.9456609894566099\n",
      "    F1 Score: 0.933920704845815\n",
      "    ROC AUC: 0.9227282452395524\n",
      "    Confusion Matrix: [[ 880   98]\n",
      " [  67 1166]]\n",
      "\n",
      "  SVM_kernel_rbf:\n",
      "    Accuracy: 0.9479873360470376\n",
      "    Precision: 0.9408517350157729\n",
      "    Recall: 0.967558799675588\n",
      "    F1 Score: 0.9540183926429429\n",
      "    ROC AUC: 0.9454358415555854\n",
      "    Confusion Matrix: [[ 903   75]\n",
      " [  40 1193]]\n",
      "\n",
      "  SVM_tol_1e_3:\n",
      "    Accuracy: 0.9484396200814111\n",
      "    Precision: 0.941594317284925\n",
      "    Recall: 0.967558799675588\n",
      "    F1 Score: 0.9544\n",
      "    ROC AUC: 0.9459470889993482\n",
      "    Confusion Matrix: [[ 904   74]\n",
      " [  40 1193]]\n",
      "\n",
      "  SVM_tol_1e_4:\n",
      "    Accuracy: 0.9479873360470376\n",
      "    Precision: 0.9408517350157729\n",
      "    Recall: 0.967558799675588\n",
      "    F1 Score: 0.9540183926429429\n",
      "    ROC AUC: 0.9454358415555854\n",
      "    Confusion Matrix: [[ 903   75]\n",
      " [  40 1193]]\n",
      "\n",
      "  Logistic Regression_C_1:\n",
      "    Accuracy: 0.9249208502939846\n",
      "    Precision: 0.9230769230769231\n",
      "    Recall: 0.9440389294403893\n",
      "    F1 Score: 0.9334402566158782\n",
      "    ROC AUC: 0.9224284626752048\n",
      "    Confusion Matrix: [[ 881   97]\n",
      " [  69 1164]]\n",
      "\n",
      "  Logistic Regression_C_0_1:\n",
      "    Accuracy: 0.926729986431479\n",
      "    Precision: 0.9233201581027668\n",
      "    Recall: 0.9472830494728305\n",
      "    F1 Score: 0.9351481184947958\n",
      "    ROC AUC: 0.9240505226914254\n",
      "    Confusion Matrix: [[ 881   97]\n",
      " [  65 1168]]\n",
      "\n",
      "  Logistic Regression_solver_liblinear:\n",
      "    Accuracy: 0.9262777023971054\n",
      "    Precision: 0.9252782193958664\n",
      "    Recall: 0.9440389294403893\n",
      "    F1 Score: 0.9345644319550381\n",
      "    ROC AUC: 0.9239622050064932\n",
      "    Confusion Matrix: [[ 884   94]\n",
      " [  69 1164]]\n",
      "\n",
      "  Logistic Regression_solver_lbfgs:\n",
      "    Accuracy: 0.9262777023971054\n",
      "    Precision: 0.9246031746031746\n",
      "    Recall: 0.9448499594484996\n",
      "    F1 Score: 0.9346169273967108\n",
      "    ROC AUC: 0.9238564725667856\n",
      "    Confusion Matrix: [[ 883   95]\n",
      " [  68 1165]]\n",
      "\n",
      "  Logistic Regression_max_iter_200:\n",
      "    Accuracy: 0.9262777023971054\n",
      "    Precision: 0.9246031746031746\n",
      "    Recall: 0.9448499594484996\n",
      "    F1 Score: 0.9346169273967108\n",
      "    ROC AUC: 0.9238564725667856\n",
      "    Confusion Matrix: [[ 883   95]\n",
      " [  68 1165]]\n",
      "\n",
      "  Logistic Regression_max_iter_100:\n",
      "    Accuracy: 0.9262777023971054\n",
      "    Precision: 0.9246031746031746\n",
      "    Recall: 0.9448499594484996\n",
      "    F1 Score: 0.9346169273967108\n",
      "    ROC AUC: 0.9238564725667856\n",
      "    Confusion Matrix: [[ 883   95]\n",
      " [  68 1165]]\n",
      "\n",
      "  Decision Tree_max_depth_10:\n",
      "    Accuracy: 0.9466304839439168\n",
      "    Precision: 0.9596042868920033\n",
      "    Recall: 0.9440389294403893\n",
      "    F1 Score: 0.9517579721995094\n",
      "    ROC AUC: 0.9469683399758183\n",
      "    Confusion Matrix: [[ 929   49]\n",
      " [  69 1164]]\n",
      "\n",
      "  Decision Tree_max_depth_5:\n",
      "    Accuracy: 0.9240162822252375\n",
      "    Precision: 0.9031037093111279\n",
      "    Recall: 0.967558799675588\n",
      "    F1 Score: 0.9342208300704777\n",
      "    ROC AUC: 0.918339727036158\n",
      "    Confusion Matrix: [[ 850  128]\n",
      " [  40 1193]]\n",
      "\n",
      "  Decision Tree_min_samples_split_4:\n",
      "    Accuracy: 0.952962460425147\n",
      "    Precision: 0.9608163265306122\n",
      "    Recall: 0.9545823195458232\n",
      "    F1 Score: 0.9576891781936534\n",
      "    ROC AUC: 0.952751282472298\n",
      "    Confusion Matrix: [[ 930   48]\n",
      " [  56 1177]]\n",
      "\n",
      "  Decision Tree_min_samples_split_2:\n",
      "    Accuracy: 0.95838986883763\n",
      "    Precision: 0.9649551752241239\n",
      "    Recall: 0.9602595296025953\n",
      "    F1 Score: 0.9626016260162602\n",
      "    ROC AUC: 0.958146124719498\n",
      "    Confusion Matrix: [[ 935   43]\n",
      " [  49 1184]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_2:\n",
      "    Accuracy: 0.5576662143826323\n",
      "    Precision: 0.5576662143826323\n",
      "    Recall: 1.0\n",
      "    F1 Score: 0.7160278745644599\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[   0  978]\n",
      " [   0 1233]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_1:\n",
      "    Accuracy: 0.9457259158751696\n",
      "    Precision: 0.9506072874493927\n",
      "    Recall: 0.9521492295214923\n",
      "    F1 Score: 0.9513776337115073\n",
      "    ROC AUC: 0.9448885206912165\n",
      "    Confusion Matrix: [[ 917   61]\n",
      " [  59 1174]]\n",
      "\n",
      "  Random Forest_n_estimators_200:\n",
      "    Accuracy: 0.9733152419719584\n",
      "    Precision: 0.9741518578352181\n",
      "    Recall: 0.9781021897810219\n",
      "    F1 Score: 0.9761230271145286\n",
      "    ROC AUC: 0.9726911766901019\n",
      "    Confusion Matrix: [[ 946   32]\n",
      " [  27 1206]]\n",
      "\n",
      "  Random Forest_n_estimators_100:\n",
      "    Accuracy: 0.9751243781094527\n",
      "    Precision: 0.9765372168284789\n",
      "    Recall: 0.9789132197891321\n",
      "    F1 Score: 0.9777237748076144\n",
      "    ROC AUC: 0.9746304340254454\n",
      "    Confusion Matrix: [[ 949   29]\n",
      " [  26 1207]]\n",
      "\n",
      "  Random Forest_max_depth_10:\n",
      "    Accuracy: 0.9570330167345092\n",
      "    Precision: 0.9508716323296355\n",
      "    Recall: 0.9732360097323601\n",
      "    F1 Score: 0.9619238476953907\n",
      "    ROC AUC: 0.9549206633528876\n",
      "    Confusion Matrix: [[ 916   62]\n",
      " [  33 1200]]\n",
      "\n",
      "  Random Forest_max_depth_5:\n",
      "    Accuracy: 0.9294436906377205\n",
      "    Precision: 0.9230164964650432\n",
      "    Recall: 0.9529602595296026\n",
      "    F1 Score: 0.9377494014365523\n",
      "    ROC AUC: 0.9263778802760488\n",
      "    Confusion Matrix: [[ 880   98]\n",
      " [  58 1175]]\n",
      "\n",
      "  Random Forest_min_samples_split_4:\n",
      "    Accuracy: 0.968340117593849\n",
      "    Precision: 0.9685737308622079\n",
      "    Recall: 0.9748580697485807\n",
      "    F1 Score: 0.9717057396928052\n",
      "    ROC AUC: 0.9674903845675419\n",
      "    Confusion Matrix: [[ 939   39]\n",
      " [  31 1202]]\n",
      "\n",
      "  Random Forest_min_samples_split_2:\n",
      "    Accuracy: 0.9746720940750792\n",
      "    Precision: 0.9742143432715552\n",
      "    Recall: 0.9805352798053528\n",
      "    F1 Score: 0.9773645917542442\n",
      "    ROC AUC: 0.9739077217022675\n",
      "    Confusion Matrix: [[ 946   32]\n",
      " [  24 1209]]\n",
      "\n",
      "  kNN_n_neighbors_3:\n",
      "    Accuracy: 0.9348710990502035\n",
      "    Precision: 0.9698015530629853\n",
      "    Recall: 0.9115977291159773\n",
      "    F1 Score: 0.939799331103679\n",
      "    ROC AUC: 0.9379052040262913\n",
      "    Confusion Matrix: [[ 943   35]\n",
      " [ 109 1124]]\n",
      "\n",
      "  kNN_n_neighbors_5:\n",
      "    Accuracy: 0.9389416553595658\n",
      "    Precision: 0.95\n",
      "    Recall: 0.9399837793998378\n",
      "    F1 Score: 0.9449653485527925\n",
      "    ROC AUC: 0.9388057956303892\n",
      "    Confusion Matrix: [[ 917   61]\n",
      " [  74 1159]]\n",
      "\n",
      "  kNN_weights_distance:\n",
      "    Accuracy: 0.9588421528720036\n",
      "    Precision: 0.9597423510466989\n",
      "    Recall: 0.9667477696674777\n",
      "    F1 Score: 0.9632323232323232\n",
      "    ROC AUC: 0.9578115126455997\n",
      "    Confusion Matrix: [[ 928   50]\n",
      " [  41 1192]]\n",
      "\n",
      "  kNN_weights_uniform:\n",
      "    Accuracy: 0.9466304839439168\n",
      "    Precision: 0.9499596448748991\n",
      "    Recall: 0.9545823195458232\n",
      "    F1 Score: 0.9522653721682848\n",
      "    ROC AUC: 0.9455938182596191\n",
      "    Confusion Matrix: [[ 916   62]\n",
      " [  56 1177]]\n",
      "\n",
      "  kNN_metric_euclidean:\n",
      "    Accuracy: 0.9466304839439168\n",
      "    Precision: 0.9499596448748991\n",
      "    Recall: 0.9545823195458232\n",
      "    F1 Score: 0.9522653721682848\n",
      "    ROC AUC: 0.9455938182596191\n",
      "    Confusion Matrix: [[ 916   62]\n",
      " [  56 1177]]\n",
      "\n",
      "  kNN_metric_manhattan:\n",
      "    Accuracy: 0.9556761646313885\n",
      "    Precision: 0.9565567176186646\n",
      "    Recall: 0.9643146796431468\n",
      "    F1 Score: 0.9604200323101777\n",
      "    ROC AUC: 0.9545499778583831\n",
      "    Confusion Matrix: [[ 924   54]\n",
      " [  44 1189]]\n",
      "\n",
      "Results for Accidents dataset with hyperparameters:\n",
      "  SVM_C_10:\n",
      "    Accuracy: 0.9904570567553993\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.49987325728770593\n",
      "    Confusion Matrix: [[3944    1]\n",
      " [  37    0]]\n",
      "\n",
      "  SVM_C_0_1:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  SVM_kernel_linear:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  SVM_kernel_rbf:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  SVM_tol_1e_3:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  SVM_tol_1e_4:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression_C_1:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression_C_0_1:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression_solver_liblinear:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression_solver_lbfgs:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression_max_iter_200:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Logistic Regression_max_iter_100:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Decision Tree_max_depth_10:\n",
      "    Accuracy: 0.9884480160723255\n",
      "    Precision: 0.15384615384615385\n",
      "    Recall: 0.05405405405405406\n",
      "    F1 Score: 0.08\n",
      "    ROC AUC: 0.5256328571917924\n",
      "    Confusion Matrix: [[3934   11]\n",
      " [  35    2]]\n",
      "\n",
      "  Decision Tree_max_depth_5:\n",
      "    Accuracy: 0.9892014063284782\n",
      "    Precision: 0.125\n",
      "    Recall: 0.02702702702702703\n",
      "    F1 Score: 0.044444444444444446\n",
      "    ROC AUC: 0.5126263145274552\n",
      "    Confusion Matrix: [[3938    7]\n",
      " [  36    1]]\n",
      "\n",
      "  Decision Tree_min_samples_split_4:\n",
      "    Accuracy: 0.9821697639377197\n",
      "    Precision: 0.09523809523809523\n",
      "    Recall: 0.10810810810810811\n",
      "    F1 Score: 0.10126582278481013\n",
      "    ROC AUC: 0.5492378309868804\n",
      "    Confusion Matrix: [[3907   38]\n",
      " [  33    4]]\n",
      "\n",
      "  Decision Tree_min_samples_split_2:\n",
      "    Accuracy: 0.9796584630838775\n",
      "    Precision: 0.07692307692307693\n",
      "    Recall: 0.10810810810810811\n",
      "    F1 Score: 0.0898876404494382\n",
      "    ROC AUC: 0.54797040386394\n",
      "    Confusion Matrix: [[3897   48]\n",
      " [  33    4]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_2:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Decision Tree_min_samples_leaf_1:\n",
      "    Accuracy: 0.9864389753892516\n",
      "    Precision: 0.16\n",
      "    Recall: 0.10810810810810811\n",
      "    F1 Score: 0.12903225806451613\n",
      "    ROC AUC: 0.5513924570958791\n",
      "    Confusion Matrix: [[3924   21]\n",
      " [  33    4]]\n",
      "\n",
      "  Random Forest_n_estimators_200:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Random Forest_n_estimators_100:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Random Forest_max_depth_10:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Random Forest_max_depth_5:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Random Forest_min_samples_split_4:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  Random Forest_min_samples_split_2:\n",
      "    Accuracy: 0.9904570567553993\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.49987325728770593\n",
      "    Confusion Matrix: [[3944    1]\n",
      " [  37    0]]\n",
      "\n",
      "  kNN_n_neighbors_3:\n",
      "    Accuracy: 0.9902059266700151\n",
      "    Precision: 0.25\n",
      "    Recall: 0.02702702702702703\n",
      "    F1 Score: 0.04878048780487805\n",
      "    ROC AUC: 0.5131332853766313\n",
      "    Confusion Matrix: [[3942    3]\n",
      " [  36    1]]\n",
      "\n",
      "  kNN_n_neighbors_5:\n",
      "    Accuracy: 0.9907081868407835\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.5\n",
      "    Confusion Matrix: [[3945    0]\n",
      " [  37    0]]\n",
      "\n",
      "  kNN_weights_distance:\n",
      "    Accuracy: 0.9899547965846308\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.49961977186311785\n",
      "    Confusion Matrix: [[3942    3]\n",
      " [  37    0]]\n",
      "\n",
      "  kNN_weights_uniform:\n",
      "    Accuracy: 0.9902059266700151\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.4997465145754119\n",
      "    Confusion Matrix: [[3943    2]\n",
      " [  37    0]]\n",
      "\n",
      "  kNN_metric_euclidean:\n",
      "    Accuracy: 0.9902059266700151\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.4997465145754119\n",
      "    Confusion Matrix: [[3943    2]\n",
      " [  37    0]]\n",
      "\n",
      "  kNN_metric_manhattan:\n",
      "    Accuracy: 0.9904570567553993\n",
      "    Precision: 0.0\n",
      "    Recall: 0.0\n",
      "    F1 Score: 0.0\n",
      "    ROC AUC: 0.49987325728770593\n",
      "    Confusion Matrix: [[3944    1]\n",
      " [  37    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_results in results_with_params.items():\n",
    "    print(f\"Results for {dataset_name} dataset with hyperparameters:\")\n",
    "    for model_name, metrics in dataset_results.items():\n",
    "        print(f\"  {model_name}:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"    {metric_name}: {value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de BRCA dataset:\n",
    "Modelos SVM:\n",
    "\n",
    "* SVM_C_10 y SVM_kernel_rbf: Ambos modelos tienen un rendimiento muy alto, con precisión perfecta y un recall ligeramente menor, lo que indica que clasifican correctamente casi todos los casos positivos y negativos.\n",
    "* SVM_C_0_1: Tiene un rendimiento ligeramente inferior, con un recall más bajo, lo que indica que no clasifica tan bien los casos positivos.\n",
    "\n",
    "Modelos de Regresión Logística:\n",
    "\n",
    "* Todos los modelos de regresión logística tienen un rendimiento muy alto, con precisión perfecta y un recall ligeramente menor, similar a los mejores modelos SVM.\n",
    "\n",
    "Modelos de Árbol de Decisión:\n",
    "\n",
    "* Decision Tree_max_depth_10, Decision Tree_max_depth_5, Decision Tree_min_samples_split_4, Decision Tree_min_samples_split_2, Decision Tree_min_samples_leaf_1: Todos estos modelos tienen un rendimiento perfecto en todas las métricas, lo que sugiere que pueden estar sobreajustados a los datos de entrenamiento.\n",
    "*Decision Tree_min_samples_leaf_2: Tiene un rendimiento muy bajo, no identificando correctamente ningún caso positivo.\n",
    "Modelos de Bosque Aleatorio:\n",
    "\n",
    "* Todos los modelos de bosque aleatorio tienen un rendimiento perfecto en todas las métricas, similar a los mejores modelos de árbol de decisión.\n",
    "\n",
    "Modelos kNN:\n",
    "\n",
    "* kNN_n_neighbors_3: Tiene un rendimiento ligeramente inferior en comparación con los otros modelos, con un recall más bajo.\n",
    "* kNN_n_neighbors_5, kNN_weights_distance, kNN_weights_uniform, kNN_metric_euclidean: Tienen un rendimiento muy alto, con precisión y recall muy buenos.\n",
    "* kNN_metric_manhattan: Tiene un rendimiento ligeramente inferior, con un recall más bajo.\n",
    "\n",
    "Viendo los datos anteriores yo no escogería ni los random forest ni los arboles de desición porque da todo 1 y estarán sobreajustados lo que haran que no sean buenos con los datos de prueba por lo que scogeré el SVM con kernel RBF, podría haber escogido otros con los mismo resultados como Logistic Regression_C_0_1 o SVM_tol_1e_4 pero me he decantado por este"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de Wine Dataset:\n",
    "\n",
    "Modelos SVM:\n",
    "\n",
    "* SVM_kernel_rbf: Tiene el mejor rendimiento entre los modelos SVM, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "\n",
    "Modelos de Regresión Logística:\n",
    "\n",
    "* Logistic Regression_C_0_1: Tiene un rendimiento ligeramente superior en comparación con otros modelos de regresión logística, con un buen equilibrio entre precisión y recall.\n",
    "\n",
    "Modelos de Árbol de Decisión:\n",
    "\n",
    "* Decision Tree_min_samples_split_4: Tiene el mejor rendimiento entre los modelos de árbol de decisión, con una precisión y recall aceptables.\n",
    "\n",
    "Modelos de Bosque Aleatorio:\n",
    "\n",
    "* Random Forest_min_samples_split_4: Tiene el mejor rendimiento entre los modelos de bosque aleatorio, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "\n",
    "Modelos kNN:\n",
    "\n",
    "* kNN_weights_distance: Tiene el mejor rendimiento entre los modelos kNN, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "\n",
    "Viendo los datos anteriores el mejor modelo es el Random Forest_min_samples_split_4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de Phishing dataset:\n",
    "\n",
    "Modelos SVM:\n",
    "\n",
    "SVM_C_10: Tiene el mejor rendimiento entre los modelos SVM, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "Modelos de Regresión Logística:\n",
    "\n",
    "Logistic Regression_C_0_1: Tiene un rendimiento ligeramente superior en comparación con otros modelos de regresión logística, con un buen equilibrio entre precisión y recall.\n",
    "Modelos de Árbol de Decisión:\n",
    "\n",
    "Decision Tree_min_samples_split_2: Tiene el mejor rendimiento entre los modelos de árbol de decisión, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "Modelos de Bosque Aleatorio:\n",
    "\n",
    "Random Forest_n_estimators_100: Tiene el mejor rendimiento entre los modelos de bosque aleatorio, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "Modelos kNN:\n",
    "\n",
    "kNN_weights_distance: Tiene el mejor rendimiento entre los modelos kNN, con una alta precisión y recall, lo que indica un buen equilibrio entre la clasificación de casos positivos y negativos.\n",
    "\n",
    "Viendo los datos anteriores el mejor modelo es el Random Random Forest_n_estimators_100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de Phishing dataset:\n",
    "\n",
    "* Modelos SVM y Regresión Logística:\n",
    "\n",
    "Todos los modelos SVM y de regresión logística tienen una alta precisión en términos de clasificar los negativos, pero no identifican correctamente ningún caso positivo, lo que se refleja en las métricas de precisión, recall y F1 score de 0.\n",
    "\n",
    "Modelos de Árbol de Decisión:\n",
    "\n",
    "* Decision Tree_max_depth_10: Tiene un rendimiento ligeramente mejor en términos de identificar casos positivos, pero aún así es bastante bajo.\n",
    "* Decision Tree_min_samples_split_4: Tiene un rendimiento ligeramente mejor en términos de identificar casos positivos, pero aún así es bastante bajo.\n",
    "\n",
    "Modelos de Bosque Aleatorio:\n",
    "\n",
    "* Todos los modelos de bosque aleatorio tienen una alta precisión en términos de clasificar los negativos, pero no identifican correctamente ningún caso positivo.\n",
    "\n",
    "Modelos kNN:\n",
    "\n",
    "* kNN_n_neighbors_3: Tiene un rendimiento ligeramente mejor en términos de identificar casos positivos, pero aún así es bastante bajo.\n",
    "\n",
    "Viendo los datos anteriores el mejor modelo es el Random Random Decision Tree_max_depth_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los datasets de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example_dataset(x, y):\n",
    "    positive_indices = y[y == 1].index[:5]\n",
    "    negative_indices = y[y == 0].index[:5]\n",
    "    example_indices = positive_indices.union(negative_indices)\n",
    "    X_example = x.loc[example_indices]\n",
    "    y_example = y.loc[example_indices]\n",
    "    return X_example, y_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dividimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_example_brca, y_example_brca = create_example_dataset(X_brca, y_brca)\n",
    "X_example_wine, y_example_wine = create_example_dataset(X_wine, y_wine)\n",
    "X_example_accidents, y_example_accidents = create_example_dataset(X_accidents, y_accidents)\n",
    "X_example_phishing, y_example_phishing = create_example_dataset(X_phishing, y_phishing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los escalamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_example_brca = scaler.fit_transform(X_example_brca)\n",
    "X_example_wine = scaler.fit_transform(X_example_wine)\n",
    "X_example_accidents = scaler.fit_transform(X_example_accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los diccionarios con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'BRCA': (X_example_brca, y_example_brca),\n",
    "    'Wine': (X_example_wine, y_example_wine),\n",
    "    'Phishing': (X_example_phishing, y_example_phishing),\n",
    "    'Accidents': (X_example_accidents, y_example_accidents)    \n",
    "}\n",
    "\n",
    "modelos_prueba = {\n",
    "    'BRCA': 'SVM_kernel_rbf',\n",
    "    'Wine': 'Random Forest_min_samples_split_4',\n",
    "    'Phishing': 'Random Forest_n_estimators_100',\n",
    "    'Accidents': 'Decision Tree_max_depth_10'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacems las preddciones con los modelos seleccionados, los evaluamos y los mostramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_prueba(model, X_test, y_test):\n",
    "    print(model)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1, roc_auc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(random_state=6)\n",
      "RandomForestClassifier(min_samples_split=8, random_state=6)\n",
      "RandomForestClassifier(random_state=6)\n",
      "DecisionTreeClassifier(max_depth=10, random_state=6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results_prueba = {}\n",
    "for dataset_name, (x, y) in datasets.items():\n",
    "    model = modelos[dataset_name+\"_\"+modelos_prueba[dataset_name]]\n",
    "\n",
    "    accuracy, precision, recall, f1, roc_auc, cm = evaluate_model_prueba(model, x, y)\n",
    "    results_prueba[dataset_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Confusion Matrix': cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BRCA dataset with hyperparameters:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "  ROC AUC: 1.0\n",
      "  Confusion Matrix: [[5 0]\n",
      " [0 5]]\n",
      "\n",
      "Results for Wine dataset with hyperparameters:\n",
      "  Accuracy: 0.7\n",
      "  Precision: 0.6666666666666666\n",
      "  Recall: 0.8\n",
      "  F1 Score: 0.7272727272727273\n",
      "  ROC AUC: 0.7000000000000001\n",
      "  Confusion Matrix: [[3 2]\n",
      " [1 4]]\n",
      "\n",
      "Results for Phishing dataset with hyperparameters:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "  ROC AUC: 1.0\n",
      "  Confusion Matrix: [[5 0]\n",
      " [0 5]]\n",
      "\n",
      "Results for Accidents dataset with hyperparameters:\n",
      "  Accuracy: 0.5\n",
      "  Precision: 0.0\n",
      "  Recall: 0.0\n",
      "  F1 Score: 0.0\n",
      "  ROC AUC: 0.5\n",
      "  Confusion Matrix: [[5 0]\n",
      " [5 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, metrics in results_prueba.items():\n",
    "    print(f\"Results for {dataset_name} dataset with hyperparameters:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BRCA y Phishing: Los modelos para estos datasets tienen un rendimiento perfecto en el dataset de ejemplo, clasificando correctamente todas las muestras.\n",
    "* Wine: El modelo tiene un rendimiento moderado, con una precisión y recall razonables, pero no perfectos.\n",
    "Accidents: El modelo tiene un rendimiento pobre, con una precisión y recall de 0, indicando que no pudo identificar ninguna muestra positiva correctamente.\n",
    "\n",
    "* Estos resultados sugieren que los modelos para BRCA y Phishing están bien ajustados para sus respectivos datasets, mientras que el modelo para Accidents necesita mejoras significativas. El modelo para Wine tiene un rendimiento aceptable, pero también podría beneficiarse de ajustes adicionales."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 532277,
     "sourceId": 975216,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1866301,
     "sourceId": 3047725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3248517,
     "sourceId": 5651459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4433814,
     "sourceId": 7613735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
